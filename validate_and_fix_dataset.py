"""
æ•°æ®é›†éªŒè¯å’Œä¿®å¤è„šæœ¬

æ­¤è„šæœ¬ç”¨äºï¼š
1. éªŒè¯æ•°æ®é›†ä¸­å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶æ˜¯å¦ä¸€ä¸€å¯¹åº”
2. ä¿®å¤ä¸åŒ¹é…çš„é—®é¢˜
3. æä¾›è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
"""

import os
import yaml
from pathlib import Path
import argparse


def check_dataset(images_dir, labels_dir):
    """
    æ£€æŸ¥æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶æ˜¯å¦ä¸€ä¸€å¯¹åº”
    
    Args:
        images_dir: å›¾åƒç›®å½•è·¯å¾„
        labels_dir: æ ‡ç­¾ç›®å½•è·¯å¾„
    
    Returns:
        dict: æ£€æŸ¥ç»“æœç»Ÿè®¡ä¿¡æ¯
    """
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    images = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        images.extend(Path(images_dir).glob(ext))
    
    # è·å–æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    labels = set(os.listdir(labels_dir))
    
    # ç»Ÿè®¡åŒ¹é…å’Œä¸åŒ¹é…çš„æ•°é‡
    matched = 0
    unmatched = 0
    unmatched_files = []
    
    # æ£€æŸ¥æ¯ä¸ªå›¾åƒæ–‡ä»¶æ˜¯å¦æœ‰å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
    for img in images:
        label_file = f"{img.stem}.txt"
        if label_file in labels:
            matched += 1
        else:
            unmatched += 1
            unmatched_files.append(str(img))
    
    # è®¡ç®—ä¸åŒ¹é…ç‡
    total_images = len(images)
    unmatched_rate = (unmatched / total_images * 100) if total_images > 0 else 0
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"æ•°æ®é›†æ£€æŸ¥ç»“æœ:")
    print(f"  æ€»å›¾åƒæ–‡ä»¶æ•°: {total_images}")
    print(f"  åŒ¹é…çš„æ–‡ä»¶å¯¹: {matched}")
    print(f"  ä¸åŒ¹é…çš„æ–‡ä»¶æ•°: {unmatched}")
    print(f"  ä¸åŒ¹é…ç‡: {unmatched_rate:.2f}%")
    
    if unmatched_files:
        print(f"  ä¸åŒ¹é…çš„æ–‡ä»¶åˆ—è¡¨:")
        for file in unmatched_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"    {file}")
        if len(unmatched_files) > 10:
            print(f"    ... è¿˜æœ‰ {len(unmatched_files) - 10} ä¸ªæ–‡ä»¶")
    
    return {
        'total_images': total_images,
        'matched': matched,
        'unmatched': unmatched,
        'unmatched_rate': unmatched_rate,
        'unmatched_files': unmatched_files
    }


def get_file_pairs(images_dir, labels_dir):
    """
    è·å–å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶å¯¹
    
    Args:
        images_dir: å›¾åƒç›®å½•
        labels_dir: æ ‡ç­¾ç›®å½•
    
    Returns:
        tuple: (åŒ¹é…çš„æ–‡ä»¶å¯¹åˆ—è¡¨, åªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾çš„æ–‡ä»¶, åªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒçš„æ–‡ä»¶)
    """
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = {}
    for ext in ['.jpg', '.jpeg', '.png']:
        for file in Path(images_dir).glob(f'*{ext}'):
            stem = file.stem
            image_files[stem] = file
    
    # è·å–æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    label_files = {}
    for file in Path(labels_dir).glob('*.txt'):
        stem = file.stem
        label_files[stem] = file
    
    # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹
    matched_pairs = []
    image_only = []
    label_only = []
    
    # æ£€æŸ¥å›¾åƒæœ‰ä½†æ ‡ç­¾æ²¡æœ‰çš„æ–‡ä»¶
    for stem, image_path in image_files.items():
        if stem in label_files:
            matched_pairs.append((image_path, label_files[stem]))
        else:
            image_only.append(image_path)
    
    # æ£€æŸ¥æ ‡ç­¾æœ‰ä½†å›¾åƒæ²¡æœ‰çš„æ–‡ä»¶
    for stem, label_path in label_files.items():
        if stem not in image_files:
            label_only.append(label_path)
    
    return matched_pairs, image_only, label_only


def validate_dataset_split(split_path, split_name):
    """
    éªŒè¯å•ä¸ªæ•°æ®é›†åˆ†å‰²ï¼ˆè®­ç»ƒé›†æˆ–éªŒè¯é›†ï¼‰
    
    Args:
        split_path: æ•°æ®é›†åˆ†å‰²è·¯å¾„
        split_name: æ•°æ®é›†åˆ†å‰²åç§°ï¼ˆ'train' æˆ– 'val'ï¼‰
    
    Returns:
        dict: éªŒè¯ç»“æœ
    """
    print(f"\néªŒè¯{split_name}é›†...")
    
    images_dir = os.path.join(split_path, 'images')
    labels_dir = os.path.join(split_path, 'labels')
    
    if not os.path.exists(images_dir):
        print(f"âŒ {split_name}é›†å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        return None
        
    if not os.path.exists(labels_dir):
        print(f"âŒ {split_name}é›†æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {labels_dir}")
        return None
    
    # ä½¿ç”¨æ–°çš„check_datasetå‡½æ•°è¿›è¡Œæ£€æŸ¥
    check_result = check_dataset(images_dir, labels_dir)
    
    # è·å–æ–‡ä»¶å¯¹ä¿¡æ¯ï¼ˆä¸ºäº†ä¿æŒå‘åå…¼å®¹ï¼‰
    matched_pairs, image_only, label_only = get_file_pairs(images_dir, labels_dir)
    
    result = {
        'total_images': check_result['total_images'],
        'total_labels': len(os.listdir(labels_dir)),
        'matched_pairs': check_result['matched'],
        'image_only': check_result['unmatched'],
        'label_only': len(label_only),
        'image_only_files': [Path(images_dir) / Path(f).name for f in check_result['unmatched_files']],
        'label_only_files': label_only
    }
    
    print(f"  æ€»å›¾åƒæ–‡ä»¶æ•°: {result['total_images']}")
    print(f"  æ€»æ ‡ç­¾æ–‡ä»¶æ•°: {result['total_labels']}")
    print(f"  åŒ¹é…çš„æ–‡ä»¶å¯¹: {result['matched_pairs']}")
    print(f"  åªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾: {result['image_only']}")
    print(f"  åªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒ: {result['label_only']}")
    
    if result['image_only'] > 0:
        print(f"  è­¦å‘Š: å‘ç° {result['image_only']} ä¸ªåªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾çš„æ–‡ä»¶")
        
    if result['label_only'] > 0:
        print(f"  è­¦å‘Š: å‘ç° {result['label_only']} ä¸ªåªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒçš„æ–‡ä»¶")
    
    return result


def fix_dataset_mismatch(split_path, split_name, action='report'):
    """
    ä¿®å¤æ•°æ®é›†ä¸åŒ¹é…é—®é¢˜
    
    Args:
        split_path: æ•°æ®é›†åˆ†å‰²è·¯å¾„
        split_name: æ•°æ®é›†åˆ†å‰²åç§°
        action: æ“ä½œç±»å‹ ('report' ä»…æŠ¥å‘Š, 'remove_image_only' åˆ é™¤åªæœ‰å›¾åƒçš„æ–‡ä»¶, 
               'remove_label_only' åˆ é™¤åªæœ‰æ ‡ç­¾çš„æ–‡ä»¶)
    """
    print(f"\nå¤„ç†{split_name}é›†ä¸åŒ¹é…é—®é¢˜...")
    
    images_dir = os.path.join(split_path, 'images')
    labels_dir = os.path.join(split_path, 'labels')
    
    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):
        return
    
    matched_pairs, image_only, label_only = get_file_pairs(images_dir, labels_dir)
    
    if action == 'remove_image_only' and image_only:
        print(f"  åˆ é™¤ {len(image_only)} ä¸ªåªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾çš„æ–‡ä»¶...")
        for image_file in image_only:
            try:
                os.remove(image_file)
                print(f"    å·²åˆ é™¤: {image_file}")
            except Exception as e:
                print(f"    åˆ é™¤å¤±è´¥ {image_file}: {e}")
    
    if action == 'remove_label_only' and label_only:
        print(f"  åˆ é™¤ {len(label_only)} ä¸ªåªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒçš„æ–‡ä»¶...")
        for label_file in label_only:
            try:
                os.remove(label_file)
                print(f"    å·²åˆ é™¤: {label_file}")
            except Exception as e:
                print(f"    åˆ é™¤å¤±è´¥ {label_file}: {e}")


def validate_dataset_config():
    """
    éªŒè¯æ•°æ®é›†é…ç½®æ–‡ä»¶
    
    Returns:
        tuple: (é…ç½®æ˜¯å¦æœ‰æ•ˆ, æ•°æ®é›†æ ¹è·¯å¾„)
    """
    config_file = 'dataset.yaml'
    if not os.path.exists(config_file):
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®é›†é…ç½®æ–‡ä»¶ dataset.yaml")
        return False, None
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        dataset_path = config.get('path')
        if not dataset_path:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æœªæŒ‡å®šæ•°æ®é›†è·¯å¾„")
            return False, None
            
        if not os.path.exists(dataset_path):
            print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return False, None
            
        return True, dataset_path
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False, None


def check_yolo_weights_compatibility():
    """
    æ£€æŸ¥YOLOæƒé‡æ–‡ä»¶å…¼å®¹æ€§
    
    Returns:
        bool: æ˜¯å¦å…¼å®¹
    """
    print("\næ£€æŸ¥YOLOæƒé‡æ–‡ä»¶å…¼å®¹æ€§...")
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    weight_paths = [
        os.path.join("runs", "detect", "train", "weights", "yolov11n.pt"),
        "yolov11n.pt"
    ]
    
    weight_found = False
    for weight_path in weight_paths:
        if os.path.exists(weight_path):
            size = os.path.getsize(weight_path) / (1024*1024)  # MB
            print(f"âœ… æ‰¾åˆ°æƒé‡æ–‡ä»¶: {weight_path} ({size:.1f} MB)")
            weight_found = True
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥åŠ è½½æƒé‡
            try:
                from ultralytics import YOLO
                model = YOLO(weight_path)
                print(f"âœ… æƒé‡æ–‡ä»¶åŠ è½½æˆåŠŸ")
                print(f"  æ¨¡å‹ä»»åŠ¡: {model.task if hasattr(model, 'task') else 'unknown'}")
                print(f"  æ¨¡å‹ç±»åˆ«æ•°: {len(model.names) if hasattr(model, 'names') else 'unknown'}")
                return True
            except Exception as e:
                print(f"âŒ æƒé‡æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                return False
    
    if not weight_found:
        print("âš ï¸  æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹")
        try:
            from ultralytics import YOLO
            model = YOLO('yolov11n.pt')
            print("âœ… é»˜è®¤æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ é»˜è®¤æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    return True


def run_comprehensive_check():
    """
    è¿è¡Œç»¼åˆæ£€æŸ¥
    
    Returns:
        bool: æ£€æŸ¥æ˜¯å¦é€šè¿‡
    """
    print("=" * 60)
    print("æ•°æ®é›†å’Œæƒé‡æ–‡ä»¶ç»¼åˆæ£€æŸ¥")
    print("=" * 60)
    
    # 1. éªŒè¯æ•°æ®é›†é…ç½®
    is_valid, dataset_path = validate_dataset_config()
    if not is_valid:
        return False
    
    # 2. éªŒè¯è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_path = os.path.join(dataset_path, 'train')
    val_path = os.path.join(dataset_path, 'val')
    
    train_result = validate_dataset_split(train_path, 'è®­ç»ƒ')
    val_result = validate_dataset_split(val_path, 'éªŒè¯')
    
    if train_result is None or val_result is None:
        return False
    
    # 3. æ£€æŸ¥æƒé‡æ–‡ä»¶å…¼å®¹æ€§
    weights_compatible = check_yolo_weights_compatibility()
    
    # 4. æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æ£€æŸ¥ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    total_issues = (train_result['image_only'] + train_result['label_only'] + 
                   val_result['image_only'] + val_result['label_only'])
    
    if total_issues > 0:
        print(f"âš ï¸  å‘ç° {total_issues} ä¸ªæ•°æ®é›†åŒ¹é…é—®é¢˜:")
        print(f"  è®­ç»ƒé›†:")
        print(f"    åªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾: {train_result['image_only']} ä¸ª")
        print(f"    åªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒ: {train_result['label_only']} ä¸ª")
        print(f"  éªŒè¯é›†:")
        print(f"    åªæœ‰å›¾åƒæ²¡æœ‰æ ‡ç­¾: {val_result['image_only']} ä¸ª")
        print(f"    åªæœ‰æ ‡ç­¾æ²¡æœ‰å›¾åƒ: {val_result['label_only']} ä¸ª")
    else:
        print("âœ… æ•°æ®é›†æ–‡ä»¶åŒ¹é…è‰¯å¥½")
    
    if weights_compatible:
        print("âœ… æƒé‡æ–‡ä»¶å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
    else:
        print("âŒ æƒé‡æ–‡ä»¶å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥")
    
    overall_success = (total_issues == 0) and weights_compatible
    if overall_success:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼æ•°æ®é›†å’Œæƒé‡æ–‡ä»¶é…ç½®æ­£ç¡®ã€‚")
    else:
        print("\nâš ï¸  å­˜åœ¨é—®é¢˜éœ€è¦å¤„ç†ã€‚")
    
    return overall_success


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®é›†éªŒè¯å’Œä¿®å¤å·¥å…·')
    parser.add_argument('--action', choices=['check', 'fix-image-only', 'fix-label-only', 'fix-all'], 
                       default='check', help='æ‰§è¡Œæ“ä½œç±»å‹')
    parser.add_argument('--split', choices=['train', 'val', 'both'], 
                       default='both', help='è¦å¤„ç†çš„æ•°æ®é›†åˆ†å‰²')
    
    args = parser.parse_args()
    
    if args.action == 'check':
        run_comprehensive_check()
        return
    
    # éªŒè¯é…ç½®
    is_valid, dataset_path = validate_dataset_config()
    if not is_valid:
        return
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œä¿®å¤æ“ä½œ
    splits_to_process = []
    if args.split == 'both':
        splits_to_process = ['train', 'val']
    else:
        splits_to_process = [args.split]
    
    for split_name in splits_to_process:
        split_path = os.path.join(dataset_path, split_name)
        if os.path.exists(split_path):
            if args.action == 'fix-image-only':
                fix_dataset_mismatch(split_path, split_name, 'remove_image_only')
            elif args.action == 'fix-label-only':
                fix_dataset_mismatch(split_path, split_name, 'remove_label_only')
            elif args.action == 'fix-all':
                fix_dataset_mismatch(split_path, split_name, 'remove_image_only')
                fix_dataset_mismatch(split_path, split_name, 'remove_label_only')


if __name__ == "__main__":
    main()


